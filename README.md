# Image-Captioning

This project implements and compares two deep learning approaches for automatic image captioning: CNN-LSTM and CNN-Transformer models. Both models use a convolutional neural network (CNN) to extract visual features from images, and then generate descriptive captions using either an LSTM-based or Transformer-based decoder.

Youâ€™ll find all the Code in the 3 notebooks above.
Feel free to explore, run the models, and compare their performance!
CaptioningAPP.py contains the UI for the Transformer model that captions images and videos as well!

Note: I wasn't able to upload the models' weights, vocab files, or extracted image features, since they're too large. So you'll have to train the model with the Flickr30k dataset from Kaggle: https://www.kaggle.com/datasets/awsaf49/flickr30k-dataset
